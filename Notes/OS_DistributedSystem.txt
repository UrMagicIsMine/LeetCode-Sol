-------------------        Ch 10 distributed System       ----------------------

What is a distributed system
1) Centralized system: state stored on a single computer
  - Simpler/Easier to understand/Can be faster for a single user
2) Distributed system: state divided over multiple computers
  - More robust (can tolerate failures)
  - More scalable (often support many users)
  - More complex
3) Complexity is bad?
  - Complex system can be less reliable
  - Getting a distributed system right is hard
  - Getting them wrong can be bad (often more important)
  - Well worth using when their power is needed
4) Examples
  - Domain Name System (DNS) - distributed lookup table of hostname -> IP
  - Facebook & Google use distributed systems extensively (massive scale/fast
  enough/very reliable)
  - Email servers (SMTP)
  - Phone networks (Land line and cellular)
5) Why build a distributed system
  - Performance/Reliability/Scaling

How to learn distributed system
1) Learn by doing
  - system discipline, experimental science, not just theory
  - Learn most by taking apart, debugging and modifying an existing system
2) Topics in Distributed systems
  - How systems fail
  - How to express your goals: SLIs, SLOs, and SLAs
  - How to combine unreliable components to make a more reliable system
  - How nodes communicate -- RPCs
  - How nodes find each other -- naming
  - How to use time in a distributed world (synchronize, stock transaction)
  - How to get agreement -- consensus (PAXOS)
  - How to persist data -- distributed storage
  - How to secure your system
  - How to operate your distributed system -- the art of SRE

What Could go wrong
1) Incomplete list of issues
  - Crash/Data Corruption/Server down/Query of death/Broken dependency/Dos attack
  Cascading failure/Data loss/Time travel/Owned/Natural disaster/Cause infrastructure
  failure/Performance cliffs/Hash collision, etc.

The many types of fail
1) Network failure: TCP/IP(communicate can or not), SSH(guards against Corruption)
lose of Connection/speed to slow
2) Network Partition (at least 2 components of system continue to run, but can't
communicate)
  - shared state diverges/lost consistency
  - Detect partition/disable nodes in all but one subgraph (maintains consistency
  at the cost of availability)
  - trade-off is the CAP principle
  - Detecting partitions: ping all N nodes/count responses R/ if R <=[N/2], halts
3) Node failures
  - Fail stop: crash/power outage/hardware failure/out of memory/disk full
  - Strategies: 1) Checkpoint state and restart (high latency), 2) Replicate state
  and fail over (high cost)
4) Byzantine failure
  - Everything that is not fail stop
  - Too many failures == solution impossible
  - turn into fail stop (checksums/assertions/timeouts)
5) Failure matrix
  - Network: worry about partitions, protocol handles the rest
  - Node fail stop: checkpoint & recover, replicate & fail over
  - Byzantine: attempt to transform into fail stop

Byzantine failure
1) Not fail stop/Traitor nodes send conflicting messages (incorrect result)
2) Caused by 1) Flaky nodes 2) Malicious nodes
3) What assumption are you making
  - Do nodes/network fail?
  - Finite computation/static or dynamic adversary/Bounded communication time
  - Fully connected network/randomized algorithms
4) Consensus: The two Generals Problem ->
  - no perfect solution
5) Byzantine Generals
  - Answers: How many byzantine node failures can a system survive? how might you
  build such a system
  - Doesn't answer: is it worth doing at all.
  - BGP[1]: all loyal generals agree on what 1st general wants
  - How many traitors can you have and still solve BGP
  - There is no solution for 3 Generals, 1 Traitor.
  - Lemma: No solution for 3m+1 generals with > m traitors

1) SLIs SLOs and SLAs
  - SLI = service level indicator (what you are measuring)
  - SLO = service level objective (how good should it be)
  - SLA = service level agreement (SLO + consequences)
2) Why study SLIs, SLOs, and SLAs
  - If you measure it, you can improve it
  - Learn what matters
  - Reliability promises are part of business
3) How many nines(5 nines)
4) What does the SLA imply for provider
  - They rarely expect their hardware or software to fail
  - When it fails they think they can fix it quickly
5) SLA requires you to have
  - Multiple VMs/Over multiple failure domains/Automatic failover/Monitoring
  Tolerance of planned outages/Automatic machine provisioning
6) Setting your SLO (SLO != SLA)
  - Different applications have different requirement
  - Be conservative at first, gain experience
  - SLO < reaction time
  - Know SLA of your dependencies
  - Bound your responsibility, Under promise, over deliver
7) Composing SLAs
  - No redundancy: P(outage) > P(dependencies having an outage)
  - W/ redundancy: P(outage) > P(outage of each replica)^(#replicas)

Class Project

1) AppEngine Pros/Cons
  - Pros: Scaling done/Authentication done/Reliable storage/Multicast done/SRE as
  a service/Simple Code
  - Cons: Costs money/Only uses Google login/Channel depricated/Needs loadtesting
  /Needs application-level Monitoring/Opaque--hard to understand

2) uWSGI Pros/Cons
  - Pros: Fixed cost/Simple/Full control
  - Cons: No authentication/No redundancy/In-memory database/Scales to one machine
  Manually deployed/One thread per connection

Paxos Simplified
1) Band go dinner Problem --- want to achieve consensus
  - Band director went home
  - People easily Distracted
  - No fun if group splits up
  - Hungry: must come to a decision fast
  - Yelling fails. Use person-to-person communication
2) Paxos almost this simple
  - What's happening?
  - Let's go for burgers!
3) Consensus
  - All computers are equivalent/Failure is no Problem/At the cost of some complexity
4) Is Paxos Hard?
  - Basic Paxos algorithm: not overly complex
  - Breakthrough: a proof that consensus was solvable
  - Paxos has a troubled publication history (Paxos Made Simple)
  - Multi-Paxos = Paxos + complexity
  - Raft is more complete and simpler
5) Alternatives to Paxos (Fault Types/Failover/Servers/Messages)
  - Byzantine: Byzantine/Instant/3M+1/Exponential
  - Paxos/Raft: Fail Stop/Instant/2M+1/Linear
  - Database Replication: Fail Stop/Takes time/M+1/Linear
6) How does Paxos work
  - Failure model(node fail/network fail/network slow)
  - Majority wins(need to ask Majority/Majority must agree)
  - Majority of servers must be up for Paxos to terminate(need 2M+1 servers to
  tolerate m failures)
  - Basic Paxos(Proposer/Acceptor/Round identifier)
7) What could go wrong
  - Failures: Acceptor(No problem as long as Majority don't fail)
  - Failures: Proposer in Prepare Phase(Another proposer takes over)
  - Failures: Proposer in Accept Phase(Another proposer finishes the job)
  - Two or more simultaneous proposers (a bit more complex/ can livelock, avoid
  with leader election)
8) Leader Election
  - Can use Paxos itself to elect a leader(what if it livelocks)
  - A simple solution is good enough: The Bully algorithm
  (Send my server ID to all peers, If I receive an ID from a peer, respond with
  my server ID, If all responses have lower IDs than mine: I am the leader. If
  my ID is higher than received ID, start my own election)
9) Paxos in the real world
  - Creating a log of agreement (Multi-Paxos)
  - Adding and removing nodes from Paxos(Naming and cluster memebership)
  - Testing and debugging is hard
  - Byzantine failure(What happens if N = INFINITY)
10) Performance
  - Basic Paxos latency (2 network round trips + 2 disk writes)
  - Multi-Paxos latency (Converges on 1 network round-trip + 1 disk write assuming
  failures are rare)
  - Want multiple sites
  - Bandwidth can be increased through(Batching operations into one Paxos instance/
  Parallel Paxos instances)

How Counterstrike Works(It's about time)
1) How does it work
  - Client-server model(lag)/Speculation
2) Progress
  - Client-server model was strongly consistent(Server is one true arbiter of what
  happened)
  - Adding speculation makes us weakly consistent(Each player observes a slightly
  different game/Server is still one true arbiter of what happened)
  - Problem: Server is lagged vs clients
3) What about the enemy (Shooting at where players were, not where they are, from
the server's perspective)
  - Lag compensation (server side: Record history of player motion/Rewind position
  to t = t-lag)

4) Clocks are Hard
  - Need (High resolution/Monotone)
  - Synchronization over a network is hard (may be impossible to get accurate enough)
  - GPS based synchronization (Used by Google's Spanner database)
5) Can we do better
  - Better predictors (Use machine learning)
  - Eliminate the server (Colyseus and Donnybrook/Makes cheating-resistance harder)
  - Optimize communication(Area of interest filtering/Randomized gunfire/Match making
  matters/Have a LAN party)
